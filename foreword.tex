%!TEX root = ts.tex

\chapter{Introduction}
\label{chp:Introduction}

We propose RCU for inclusion into C++26.
This paper contains proposed rationale to support RCU into C++26 as
well as the interface and wording for RCU, a technique for safe deferred
reclamation.
We further propose that the wording in Section~\ref{saferecl.rcu}
be adopted as a new ``Safe reclamation'' chapter of the IS, and we
anticipate that hazard pointers would be covered by another section of
this same chapter.

The purpose of adding RCU to the IS is to provide a small number of
known-good implementations of RCU in standard libraries.
RCU is easy to get wrong, and one purpose standard libraries is to
provide good implementations of things that are easy to get wrong.

\section{Proposed Entry to C++26 IS}
\label{sec:Proposed Entry to C++26 IS}

A near-superset of this proposal is implemented in the Folly RCU library.
This library has used in production for several years, so we have good
implementation experience for the proposed variant of RCU.

This proposal is identical to that in Concurrency TS 2.
We expect that the proposal in Concurrency TS 2 will change over
time, for example, adding some of the features that are present in
the Folly RCU library or in the Linux kernel.
Such features might include:

\begin{enumerate}
\item	Multiple RCU domains.
	For example, SRCU provides these in the Linux kernel.
	However, RCU was in the Linux for four years before
	this was needed, so it is not in this proposal for C++26.
\item	Special-purpose RCU implementations.
	For example, the Linux kernel has specialized implementations
	for preemptible environments, single-CPU systems,
	as well as three additional implementations required by
	the Linux kernel's tracing and extended Berkeley Packet
	Filter (eBPF) use cases.
	However, none of these seem applicable to userspace applications,
	so none of them are in this proposal for C++26.
\item	Polling grace-period-wait APIs.
	These allow non-blocking algorithms to interface with RCU
	grace periods, for example, in the Linux kernel, they allow
	NMI handlers to do RCU updates.
	(NMI handlers could do RCU readers from the get-go.)
	However, RCU was in the Linux kernel for more than a decade before
	such APIs were needed, so they are not in this proposal for C++26.
\item	Async-friendly APIs for RCU's blocking APIs.
	These might leverage the aforementioned polling APIs.
	However, more work is required to determine exactly what support
	is required, so they are not in this proposal for C++26.
\item	A free function similar to \tcode{rcu_retire} that uses
	an \tcode{rcu_obj_base} if available, but which invokes
	\tcode{rcu_retire} if not.
	(Suggested by Tomasz Kami\'{n}ski.)
	However, this facility has not yet been spotted in the wild,
	so it is not in this proposal for C++26.
\item	A memory allocator might be supplied for the use of
	\tcode{rcu_retire}.
	Please note that if different allocators can be supplied to
	different calls to \tcode{rcu_retire}, then there must be a way
	to tag the allocated memory with the corresponding deleter.
	However, this facility has not yet been spotted in the wild,
	so it is not in this proposal for C++26.

	In the meantime, users needing full control over memory allocation
	can use the \tcode{rcu_obj_base} class's \tcode{.retire()}
	member function.
	With this instrusive approach, RCU need never allocate memory.

	In their turn, library implementers have a number of
	\tcode{rcu_retire()} memory-provisioning strategies at their
	disposal give the current RCU API proposed for C++26:

	\begin{enumerate}
	\item	Never allocate.
		Instead, on each call to \tcode{rcu_retire()}, invoke
		\tcode{rcu_synchronize()} then invoke the deleter.
	\item	Preallocate at least two blocks of memory, each containing
		some reasonable number of slots to record retired objects
		awaiting deletion.
		Each block must also inherit from \tcode{rcu_obj_base}.
		Fill in slots of the current block until either it fills,
		memory runs low, or some reasonable period of time has
		elapsed, then pass that block to \tcode{.retire()}.
		Switch to the next block.
		When a given block's deleter is invoked, in turn invoke
		the deleter on each slot and then make the block available
		for use by subsequent \tcode{rcu_retire()} invocations.
		If \tcode{rcu_retire()} runs out of blocks, fall back
		to strategy \#a.
	\item	Proceed as in strategy \#b, but if \tcode{rcu_retire()}
		runs out of blocks, allocate some more.
		If memory allocation fails, fall back to strategy \#a.
	\item	Proceed as in strategy \#c, but free blocks if a glut
		builds up.
	\item	Proceed as in strategy \#d, but free each block within
		its deleter.
	\end{enumerate}

\item	APIs could be provided to allow the user control over when
	deleters are scheduled and in what context they are invoked.
	Possibilities for this control include special worker threads,
	a ``perform RCU reclamation now'' function, use of timer handlers,
	or use of non-thread executors.
	In the meantime, implementations can choose to invoke deleters
	from \tcode{rcu_synchronize()} and \tcode{rcu_barrier()}.
	They may also choose to invoke deleters from \tcode{.retire()}
	and \tcode{rcu_retire()}, but doing so restricts users from
	acquiring a given resource when invoking these functions that
	is also acquired in a deleter passes to either of these functions.
	However, there is very little implementation experience with
	such a facility, and none that we are aware of in C++.
	This facility is thus not included in this proposal for C++26.
\item	Memory-allocator interfaces providing RCU-mediated typesafe
	memory could be provided similar to the Linux kernel's
	\tcode{SLAB_TYPESAFE_BY_RCU}.
	In this scheme, an object from such an allocator can be freed
	and reallocated immediately, even in presence of pre-existing
	region of RCU protection.
	However, given such a region, such an object cannot be reallocated
	as some other type.
	The object can change type only after all pre-existing regions
	of RCU protection complete.
	The readers must do some sort of verification, for example,
	mediated by reference counting, locking, or sequence locking.
	However, a C++ implementation of this facility has not yet been
	spotted in the wild, so it is not in this proposal for C++26.
\item	In order to wait for all pre-existing regions of RCU protection,
	the implementation must find them all.
	There are a number of ways of doing this, including:
	(1)~Having \tcode{rcu_domain::lock} make the running thread known
	to RCU if it is not already known (used by one of the userspace
	RCU implementations),
	(2)~Providing some means for iterating over all threads (used
	by some Linux-kernel RCU flavors), and
	(3)~Using a hashing or sharding technique to track readers
	independently of the running threads (used by some textbook
	implementations adapted for small constrained systems).
	One alternative not explicitly supported by this initial
	proposal is to provide thread-registration API members.
	There is implementation experience with this technique,
	for example, the C-language userspace RCU provide
	\tcode{rcu_register_thread()} and \tcode{rcu_unregister_thread()}
	to cause userspace RCU's grace-period computation to start
	or stop paying attention to the calling \tcode{std::thread},
	respectively.

	However, there is no implementation experience with any C++
	RCU implementation that we are aware of.
	This facility is thus not included in this proposal for C++26.
\item	Numerous efficiency-oriented APIs.
	For but one example, the Linux kernel has an alternative
	\tcode{rcu_access_pointer()} that can be used in place
	of \tcode{rcu_dereference()} (Linux-kernelese for ``consume load'')
	when the resulting pointer will not be dereferenced
	(for example, when it is only going to be compared to \tcode{NULL}).
	But it is not clear which (if any) of these would be accepted
	into the Linux kernel today, given the properties of modern
	computer hardware.
	Therefore, these are not in this proposal for C++26.
\end{enumerate}

The snapshot library described in P0561R5 (``RAII Interface for Deferred
Reclamation'') provides an easy-to-use deferred-reclamation facility
applying only to a single object which is intended to be based upon
either RCU or Hazard Pointers.
It cannot replace either RCU or Hazard Pointers.

\begin{table*}
\renewcommand*{\arraystretch}{1.25}
\footnotesize
\centering
\begin{tabular}{l|lll}
	Property
		& Reference Counting
			& Hazard Pointers
				& RCU \\
%		  RC	  HP	  RCU \\
	\hline
	\hline
	Readers
		& Slow and unscalable
			& \emph{Fast and scalable}
				& \emph{Fast and scalable} \\
	\hline
	Unreclaimed Objects
		& \emph{Bounded}
			& \emph{Bounded}
				& Unbounded \\
%	\hline
%	Protection Duration
%		& Can be long
%			& Can be long
%				& Must bound duration \\
	\hline
	Traversal Retries?
		& If object deleted
			& If object deleted
				& \emph{Never} \\
	\hline
	Reclamation latency?
		& \emph{Fast}
			& Slow
				& Slow \\
\end{tabular}
\caption{High-Level Comparison of Deferred-Reclamation Techniques}
\label{tab:High-Level Comparison of Deferred-Reclamation Techniques}
\end{table*}

The Hazard Pointers library described in D2530R0 (``Why Hazard Pointers
Should Be in C++26'').
As a very rough rule of thumb, Hazard Pointers can be considered to be
a scalable replacement for reference counters and RCU can be considered
to be a scalable replacement for reader-writer locking.
A high-level comparison of reference counting, Hazard Pointers, and RCU
is displayed in
Table~\ref{tab:High-Level Comparison of Deferred-Reclamation Techniques}.

Note that we are making this working paper available before Concurrency
TS2 been published, which some might feel is unconventional.
On the other hand, Paul was asked to begin this effort in 2014, it is now
2022, and C++ implementations have been used in production for some time,
perhaps most notably the Folly RCU library.

\section{Feature-Test Macro}
\label{sec:Feature-Test Macro}

We propose a new feature-test macro
\tcode{__cpp_lib_rcu} be added to Section~17.3.2 of the IS.

\section{Comparison Tables}
\label{sec:Comparison Tables}

Although RCU can be applied to a great many use cases, its most common
use case is as a replacement for reader-writer locking.
The reader-writer usage patterns most susceptible to conversion to RCU
are those where a value is computed while read-holding that lock, then
used after releasing that same lock.

\begin{table*}
\renewcommand*{\arraystretch}{1.25}
\footnotesize
\centering
\begin{tabular}{|l|l|}
	\hline
	With Reader-Writer Locking
		& With RCU in the intrusive style\\
%	rwlock  & RCU \\
	\hline
	\tcode{struct Data { /* members */ };}
		& \tcode{struct Data : std::rcu_obj_base<Data> { /* members */ };} \\
	\hline
	\tcode{Data* data_;}
		& \tcode{std::atomic<Data*> data_;} \\
	\tcode{std::shared_mutex m_;}
		& \\
	\hline
	\tcode{template <typename Func>}
		& \tcode{template <typename Func>} \\
	\tcode{Result reader_op(Func fn) \{}
		& \tcode{Result reader_op(Func fn) \{} \\
	\tcode{  std::shared_lock<std::shared_mutex> l(m_);}
		& \tcode{  std::scoped_lock l(std::rcu_default_domain());} \\
	\tcode{  Data* p = data_;}
		& \tcode{  Data* p = data_;} \\
	\tcode{  // fn should not block too long or call update()}
		& \tcode{  // fn should not block too long or call} \\
		& \tcode{  // rcu_synchronize(), rcu_barrier(), or} \\
		& \tcode{  // rcu_retire(), directly or indirectly} \\
	\tcode{  return fn(p);}
		& \tcode{  return fn(p);} \\
	\tcode{\}}
		& \tcode{\}} \\
	\hline
	\tcode{// May be called concurrently with reader_op}
		& \tcode{// May be called concurrently with reader_op} \\
	\tcode{void update(Data* newdata) \{}
		& \tcode{void update(Data* newdata) \{} \\
	\tcode{  Data* olddata;}
		& \tcode{  Data* olddata = data_.exchange(newdata);} \\
	\tcode{  \{}
		& \\
	~~\tcode{    std::unique_lock<std::shared_mutex> wlock(m_);}
		& \\
	~~\tcode{    olddata = std::exchange(data_, newdata);}
		& \\
	\tcode{  \}}
		& \\
	\tcode{  delete olddata; // reclaim *olddata immediately}
		& \tcode{  olddata->retire(); // reclaim *olddata when safe} \\
	\tcode{\}}
		& \tcode{\}} \\
	\hline
\end{tabular}
\caption{Comparison Table for Reader-Writer Locking and Intrusive RCU}
\label{tab:Comparison Table for Reader-Writer Locking and Intrusive RCU}
\end{table*}

Table~\ref{tab:Comparison Table for Reader-Writer Locking and Intrusive RCU}
compares reader-writer locking and intrusive RCU, that is, when the
RCU-protected data items inherit from \tcode{std::rcu_obj_base<T>} and
use the \tcode{->retire()} member function.

\begin{table*}
\renewcommand*{\arraystretch}{1.25}
\footnotesize
\centering
\begin{tabular}{|l|l|}
	\hline
	With Reader-Writer Locking
		& With RCU in the non-intrusive style\\
%	rwlock  & RCU \\
	\hline
	\tcode{struct Data { /* members */ };}
		& \tcode{struct Data { /* members */ };} \\
	\hline
	\tcode{Data* data_;}
		& \tcode{std::atomic<Data*> data_;} \\
	\tcode{std::shared_mutex m_;}
		& \\
	\hline
	\tcode{template <typename Func>}
		& \tcode{template <typename Func>} \\
	\tcode{Result reader_op(Func fn) \{}
		& \tcode{Result reader_op(Func fn) \{} \\
	\tcode{  std::shared_lock<std::shared_mutex> l(m_);}
		& \tcode{  std::scoped_lock l(std::rcu_default_domain());} \\
	\tcode{  Data* p = data_;}
		& \tcode{  Data* p = data_;} \\
	\tcode{  // fn should not block too long or call update()}
		& \tcode{  // fn should not block too long or call} \\
		& \tcode{  // rcu_synchronize(), rcu_barrier(), or} \\
		& \tcode{  // rcu_retire(), directly or indirectly} \\
	\tcode{  return fn(p);}
		& \tcode{  return fn(p);} \\
	\tcode{\}}
		& \tcode{\}} \\
	\hline
	\tcode{// May be called concurrently with reader_op}
		& \tcode{// May be called concurrently with reader_op} \\
	\tcode{void update(Data* newdata) \{}
		& \tcode{void update(Data* newdata) \{} \\
	\tcode{  Data* olddata;}
		& \tcode{  Data* olddata = data_.exchange(newdata);} \\
	\tcode{  \{}
		& \\
	~~\tcode{    std::unique_lock<std::shared_mutex> wlock(m_);}
		& \\
	~~\tcode{    olddata = std::exchange(data_, newdata);}
		& \\
	\tcode{  \}}
		& \\
	\tcode{  delete olddata; // reclaim *olddata immediately}
		& \tcode{  std::rcu_retire(olddata); // reclaim *olddata when safe} \\
	\tcode{\}}
		& \tcode{\}} \\
	\hline
\end{tabular}
\caption{Comparison Table for Reader-Writer Locking and Non-Intrusive RCU}
\label{tab:Comparison Table for Reader-Writer Locking and Non-Intrusive RCU}
\end{table*}

Table~\ref{tab:Comparison Table for Reader-Writer Locking and Non-Intrusive RCU}
compares reader-writer locking and non-intrusive RCU, that is, when the
RCU-protected data items do \emph{not} inherit from
\tcode{std::rcu_obj_base<T>} and instead use the \tcode{std::rcu_retire()}
free function.

\begin{table*}
\renewcommand*{\arraystretch}{1.25}
\footnotesize
\centering
\begin{tabular}{|l|l|}
	\hline
	With Reader-Writer Locking
		& With RCU in the synchronous style\\
%	rwlock  & RCU \\
	\hline
	\tcode{struct Data { /* members */ };}
		& \tcode{struct Data { /* members */ };} \\
	\hline
	\tcode{Data* data_;}
		& \tcode{std::atomic<Data*> data_;} \\
	\tcode{std::shared_mutex m_;}
		& \\
	\hline
	\tcode{template <typename Func>}
		& \tcode{template <typename Func>} \\
	\tcode{Result reader_op(Func fn) \{}
		& \tcode{Result reader_op(Func fn) \{} \\
	\tcode{  std::shared_lock<std::shared_mutex> l(m_);}
		& \tcode{  std::scoped_lock l(std::rcu_default_domain());} \\
	\tcode{  Data* p = data_;}
		& \tcode{  Data* p = data_;} \\
	\tcode{  // fn should not block too long or call update()}
		& \tcode{  // fn should not block too long or call} \\
		& \tcode{  // rcu_synchronize(), rcu_barrier(), or} \\
		& \tcode{  // rcu_retire(), directly or indirectly} \\
	\tcode{  return fn(p);}
		& \tcode{  return fn(p);} \\
	\tcode{\}}
		& \tcode{\}} \\
	\hline
	\tcode{// May be called concurrently with reader_op}
		& \tcode{// May be called concurrently with reader_op} \\
	\tcode{void update(Data* newdata) \{}
		& \tcode{void update(Data* newdata) \{} \\
	\tcode{  Data* olddata;}
		& \tcode{  Data* olddata = data_.exchange(newdata);} \\
	\tcode{  \{}
		& \\
	~~\tcode{    std::unique_lock<std::shared_mutex> wlock(m_);}
		& \\
	~~\tcode{    olddata = std::exchange(data_, newdata);}
		& \\
	\tcode{  \}}
		& \tcode{  std::rcu_synchronize(); // wait until it’s safe} \\
	\tcode{  delete olddata; // reclaim *olddata immediately}
		& \tcode{  delete olddata; // then reclaim *olddata} \\
	\tcode{\}}
		& \tcode{\}} \\
	\hline
\end{tabular}
\caption{Comparison Table for Reader-Writer Locking and Synchronous RCU}
\label{tab:Comparison Table for Reader-Writer Locking and Synchronous RCU}
\end{table*}

Table~\ref{tab:Comparison Table for Reader-Writer Locking and Synchronous RCU}
compares reader-writer locking and synchronous RCU, that is, when the
RCU updater does an explicit wait for readers.
When using this style, RCU-protected data items need not inherit from
\tcode{std::rcu_obj_base<T>}.

\section{History}
\label{sec:History}

More detailed history may be found here:
\url{https://github.com/paulmckrcu/wg21-rcu-C-26.git}.

\subsection{Changes From P2545R1 to P2545R2}
\label{sec:Changes From P2545R1 to P2545R2}

\begin{itemize}
\item	Prototype a private constructor for \tcode{rcu_domain} in response
	to guidance during 2022 Kona LEWG review.
\item	Record straw polls from 2022 Kona LEWG review and from
	September 2022 virtual LEWG review.
\item	Update ``Tony Tables'' to ``Comparison Tables'' in response to
	guidance during 2022 Kona LEWG review.
\item	Mention a number of longer-term possible changes:
	\begin{itemize}
	\item	Provide means for user to control the context in
		which deleters are invoked and the timing of their
		invocation.
	\item	RCU-mediated typesafe memory, perhaps similar to the
		Linux kernel's \tcode{SLAB_TYPESAFE_BY_RCU}.
	\item	Manual thread registration for threads other than
		\tcode{std::thread}, in response to discussions during
		2022 Kona LEWG review.
	\item	Give user and implementer advice on \tcode{rcu_retire()}
		metadata handling.
	\end{itemize}
\end{itemize}

\subsection{Kona 2022}
\label{sec:Kona 2022}

This paper updates P2545R1 based on discussions in LEWG and offline
at the Kona meeting.
Notes may be found here:

\begin{itemize}
\item	\url{https://docs.google.com/document/d/1QWFqwcJ6W2QOYr0ofyigU6Ej-XiNLGQfkTUf_6PZLZk/edit#}
\item	\url{https://github.com/cplusplus/papers/issues/1206#issuecomment-1310849132}
\end{itemize}

LEWG straw polls were as shown in the following sections.

\subsubsection{Poll 1}
\label{sec:kona2022:Poll 1}

Remove the defaulted \tcode{rcu_domain} parameter from
\tcode{rcu_synchronize}, \tcode{rcu_barrier}, \tcode{rcu_retire}, and
\tcode{rcu_obj_base::retire}.

\begin{tabular}{c|c|c|c|c}
SF & F &  N & A & SA \\
\hline
 4 & 5 & 12 & 1 &  0 \\
\end{tabular}

Attendance: 23 (in-person) + 7 (online) \\
\# of Authors: 2 \\
Author Position: 2 x N \\
Outcome: No consensus

\subsubsection{Poll 2}
\label{sec:kona2022:Poll 2}

Remove \tcode{rcu_domain} (but keep \tcode{rcu_default_domain} that returns a BasicLockable object).

\begin{tabular}{c|c|c|c|c}
SF & F &  N & A & SA \\
\hline
 3 & 8 &  1 & 7 &  0 \\
\end{tabular}

Attendance: 22 (in-person) + 7 (online) \\
\# of Authors: 2 \\
Author Position: 2 x WA \\
Outcome: No consensus

\subsubsection{Poll 3}
\label{sec:kona2022:Poll 3}

Send P2545R1 (why RCU should be in C++26) to Library for C++26 classified as B3 - addition, to be confirmed with a Library Evolution electronic poll.

\begin{tabular}{c|c|c|c|c}
SF & F &  N & A & SA \\
\hline
10 & 7 &  1 & 2 &  0 \\
\end{tabular}

Attendance: 25 (in-person) + 7 (remote) \\
\# of Authors: 2 \\
Author Position: 2 x SF \\
Outcome: Consensus

Statement from ``weakly against'' voter: I want to get rid of the object
and have a private constructor.

\subsubsection{Action Items}
\label{sec:kona2022:Action Items}

\begin{itemize}
\item	Add a section discussing thread registration (done).
\item	Get feedback from implementers.
\item	Bikeshed \tcode{rcu_obj_base}.
\item	Make \tcode{rcu_domains} constructor private (done).
\end{itemize}

\subsection{September 20 2022 LEWG Teleconference}
\label{sec:September 20 2022 LEWG Teleconference}

This paper updates P2545R0 based on discussions at LEWG and offlist.
Notes may be found here:

\begin{itemize}
\item	\url{https://wiki.edg.com/bin/view/Wg21telecons2022/P2545?twiki_redirect_cache=93b9b23e9c2596b6802a09f9f5ffb9bd}
\item	\url{https://github.com/cplusplus/papers/issues/1206#issuecomment-1256428844}
\end{itemize}

\subsubsection{Poll}
\label{sec:LEWG-2022-09-20:Poll}

RCU should target the International Standard instead of the Concurrency Technical Specification v2.

\begin{tabular}{c|c|c|c|c}
SF & F &  N & A & SA \\
\hline
10 & 7 &  1 & 2 &  0 \\
\end{tabular}

Attendance: 25 \\
\# of Authors: 4 \\
Author Position: 4 x SF \\
Outcome: Consensus in favor.

Statements from ``weakly against'' voters:

\begin{itemize}
\item	More fleshed out motivation could change my ``A'' to ``F''.
\item	More evidence of existing practice might change my mind.
\end{itemize}

\subsection{Changes From P2545R0 to P2545R1}
\label{sec:Changes From P2545R0 to P2545R1}

These changes to P2545R0 resulted in P2545R1, based on discussions
in virtual SG1 and LEWG meetings:

\begin{itemize}
\item	Add ``Tony Tables'' for intrusive, non-intrusive, and
	synchronous use cases.
\item	Switch from experimental to \tcode{std::} namespace.
\item	Provide rationale for adding RCU to the IS.
\item	Add a feature-test macro.
\item	Add a list of C++ RCU implementations.
\item	Add Fedor Pikus quote about large concurrent applications
	and inadvertent uses of RCU.
\item	Add a list of publications showing performance benefits of RCU.
\item	Mention a number of longer-term possible changes:
	\begin{itemize}
	\item	Async-friendly RCU APIs.
	\item	A free function similar to \tcode{rcu_retire()} that
		uses an \tcode{rcu_obj_base} if available and invokes
		\tcode{rcu_retire()} if not.
	\end{itemize}
\end{itemize}

\subsection{Older History}
\label{sec:Older History}

This paper updates P2545R0 based on discusssions in SG1 and LEWG.

P2545R0 was derived from N4895, which was in turn based on P1122R4.

P1122R4 is a successor to the RCU portion of P0566R5, in response to
LEWG’s Rapperswil 2018 request that the two techniques be split into
separate papers.

This is proposed wording for Read-Copy-Update [P0461], which is
a technique for safe deferred resource reclamation for optimistic
concurrency, useful for lock-free data structures.
Both RCU and hazard pointers have been progressing steadily through SG1
based on years of implementation by the authors, and are in wide use in
MongoDB (for Hazard Pointers), Facebook, and Linux OS (RCU).

We originally decided to do both papers' wording together to illustrate
their close relationship, and similar design structure, while hopefully
making it easier for the reader to review together for this first
presentation.
As noted above, they have been split on the committee's request.

This wording is based P0566r5, which in turn was based on that of on
n4618 draft [N4618].

\section{Source-Code Access}
\label{sec:Source-Code Access}

This section presents C++ reference implementations, other
C++ implementations, additional implementations and use cases,
and performance implications.

Counting the two reference implementation, this section points out
eleven implementations of RCU-like mechanisms in C++.

\subsection{Reference C++ Implementations}
\label{sec:Reference C++ Implementations}

The Folly library is open source, and its RCU implementation may be
accessed here:

\begin{itemize}
\item	https://github.com/facebook/folly/blob/main/folly/synchronization/Rcu.h
\item	https://github.com/facebook/folly/blob/main/folly/synchronization/Rcu-inl.h
\item	https://github.com/facebook/folly/blob/main/folly/synchronization/Rcu.cpp
\end{itemize}

There is an additional reference implementation of this proposal.
Unlike the Folly library's version, this reference implementation is
not production quality.
However, it is quite a bit simpler, having delegated the difficult parts
to the C-language userspace RCU library:

\begin{itemize}
\item	https://github.com/paulmckrcu/RCUCPPbindings/tree/master/Test/paulmck
\item	https://liburcu.org
\end{itemize}

\subsection{Other C++ Implementations}
\label{sec:Other C++ Implementations}

Maxim Khizhinsky added a C++ implementation of RCU to his libcds
around 2017.
URL: \url{https://github.com/khizmax/libcds/tree/master/cds/urcu}

Avi Kivity added a C++ implementation of RCU to the OSv kernel in
2010.
URL: \url{https://github.com/cloudius-systems/osv/blob/master/include/osv/rcu.hh}

Google uses an internally developed C++ RCU implementation alluded to by
Andrew Hunter's and Geoffrey Romer's P0561 C++ working paper.
This implementation makes use of restartable sequences in addition to
facilities defined in the standard.
URL: \url{https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2020/p0561r5.html}

Isaac Gelado and Michael Garland describe use of a CUDA/C++ RCU in GPU
programming in their 2019 PPoPP paper entitled ``Throughput-Oriented
GPU Memory Allocation''.
URL: \url{https://dl.acm.org/doi/10.1145/3293883.3295727}
% Per email from Isaac Gelado on September 21, 2022.

M\'arton et al.~present a sample C++ implementation in their paper
entitled ``High-level C++ Implementation of the Read-Copy-Update
Pattern'', which appeared in the 2017 IEEE 14\textsuperscript{th}
International Scientific Conference on Informatics.
URL: \url{https://martong.github.io/high-level-cpp-rcu_informatics_2017.pdf}
The corresponding journal paper appeared in the September 2018 Acta
Electrotechnica et Informatica.

In 2016, Pedro Ramalhete and Andreia Correia produced a C++ prototype
implementation of RCU in the ConcurrencyFreaks GitHub repository.
URL: \url{https://github.com/pramalhe/ConcurrencyFreaks/tree/master/CPP/papers/gracesharingurcu}
This appeared in the August 2017 issue of ACM SIGPLAN Notices.
URL: \url{https://dl.acm.org/doi/abs/10.1145/3155284.3019021}

Peter Goodman produced a prototype C++ implementation of RCU in his
GitHub repository in 2012.
URL: \url{https://github.com/pgoodman/rcu}

StackExchange user Jamal posted a C++ RCU-like linked-list algorithm
in 2017.
URL: \url{https://codereview.stackexchange.com/questions/151936/rcu-in-c11-using-stdshared-ptr-and-a-little-more}.

Gamsa et al.~describe an RCU-like implementation within the Tornado
and K42 research operating systems, both of which were coded in C++.
Sections~5.2 and~5.3 of their 1999 OSDI paper entitled ``Tornado: Maximizing
Locality and Concurrency in a Shared Memory Multiprocessor Operating
System'' gives an overview of their RCU-like mechanism for providing
what they call ``existence guarantees''.
URL: \url{https://www.usenix.org/legacy/events/osdi99/full_papers/gamsa/gamsa.pdf}

There are implementations of RCU-like mechanisms in proprietary
applications, but these cannot be divulged to the committee without the
permission of their respective copyright holders.
However, in the words of Fedor Pikus:

\begin{quote}
	In fact, you may already be using the RCU approach in your program
	without realizing it! Wouldn't that be cool? But careful now:
	you may be already using the RCU approach in your program in a
	subtly wrong way. I'm talking about the kind of way that makes
	your program pass every test you can throw at it and then crash
	in front of your most important customer (but only when they
	run their most critical job, not when you try to reproduce
	the problem).
\end{quote}

URL: {\scriptsize \url{https://cppcon2017.sched.com/event/BgtF/read-copy-update-then-what-rcu-for-non-kernel-programmers}}

With these words, Fedor has pinpointed a major motivation for adding
RCU to the C++ standard: To provide a smaller number of known-good RCU
implementations to C++ users.

\subsection{Other Use Cases}
\label{sec:Other Use Cases}

The C-language userspace RCU library appeared around 2009.
The QEMU project created its own version of this library in 2015.
URL: \url{https://liburcu.org}

A list of additional RCU implementations in a variety of languages
may be found in Sections~9.5.5, 9.5.5.2, and~9.6.3.3 of
``Is Parallel Programming Hard, And, If So, What Can You Do About It?''.
URL: \url{https://kernel.org/pub/linux/kernel/people/paulmck/perfbook/perfbook-e2.pdf}

RCU is used heavily in the Linux kernel:

\begin{enumerate}
\item	\url{http://www.rdrop.com/~paulmck/RCU/linuxusage.html}
\item	\url{http://www.rdrop.com/~paulmck/techreports/survey.2012.09.17a.pdf}
\item	\url{http://www.rdrop.com/~paulmck/techreports/RCUUsage.2013.02.24a.pdf}
\item	\url{https://dl.acm.org/doi/10.1145/3421473.3421481}
\end{enumerate}

\subsection{Performance Implications}
\label{sec:Performance Implications}

RCU provides the best results in read-mostly situations involving linked
data structures, and is most often used as a replacement for reader-writer
locking.
Experience in the Linux kernel indicates that well over half of the
situations to which reader-writer locking is applied can be handled
by RCU.
RCU has provided orders-of-magnitude performance and scalability
improvements in many situations, a few of which are listed below:

\begin{enumerate}
\item	\url{https://lwn.net/Kernel/Index/#Read-copy-update}
\item	\url{http://www2.rdrop.com/~paulmck/RCU/hart_ipdps06.pdf}
\item	\url{https://lkml.org/lkml/2004/8/20/137}
\item	\url{https://www.linuxjournal.com/article/7124}
\item	\url{https://www.linuxjournal.com/article/6993}
\item	\url{http://www2.rdrop.com/~paulmck/RCU/rcu.FREENIX.2003.06.14.pdf}
\item	\url{http://www2.rdrop.com/~paulmck/RCU/rcu.2002.07.08.pdf}
\item	\url{http://www2.rdrop.com/~paulmck/RCU/rclock_OLS.2001.05.01c.pdf}
\item	\url{https://docs.google.com/document/d/1X0lThx8OK0ZgLMqVoXiR4ZrGURHrXK6NyLRbeXe3Xac/edit?usp=sharing}
\end{enumerate}

Additional information may be found in Section~9.5.4 of the aforementioned
``Is Parallel Programming Hard, And, If So, What Can You Do About It?''.

\section{Acknowledgments}
\label{sec:Acknowledgments}

We owe special thanks to Jens Maurer, Arthur O'Dwyer, and Geoffrey Romer
for their many contributions to this effort.
